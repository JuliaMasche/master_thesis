{
        "word_embedding": "glove",
        "neural network": "rnn",
        "dataset": "../data/news/tsv/dataset_2000/",
        "learning_rate": 0.1,
        "max epoch": 100,
        "mini batch size": 16,
        "seed": 5,
        "performance_measure": "g-mean"
}{
                       "alt.atheism": {
                                              "precision": 0.3125,
                                              "recall": 0.5,
                                              "f1-score": 0.38461538461538464,
                                              "support": 10
                       },
                       "sci.electronics": {
                                              "precision": 0.2,
                                              "recall": 0.14285714285714285,
                                              "f1-score": 0.16666666666666666,
                                              "support": 7
                       },
                       "sci.crypt": {
                                              "precision": 0.3333333333333333,
                                              "recall": 0.3333333333333333,
                                              "f1-score": 0.3333333333333333,
                                              "support": 3
                       },
                       "comp.sys.mac.hardware": {
                                              "precision": 0.5576923076923077,
                                              "recall": 0.5272727272727272,
                                              "f1-score": 0.5420560747663552,
                                              "support": 55
                       },
                       "rec.sport.baseball": {
                                              "precision": 0.6746987951807228,
                                              "recall": 0.8888888888888888,
                                              "f1-score": 0.7671232876712328,
                                              "support": 63
                       },
                       "comp.sys.ibm.pc.hardware": {
                                              "precision": 0.0,
                                              "recall": 0.0,
                                              "f1-score": 0.0,
                                              "support": 5
                       },
                       "talk.politics.mideast": {
                                              "precision": 0.0,
                                              "recall": 0.0,
                                              "f1-score": 0.0,
                                              "support": 2
                       },
                       "sci.space": {
                                              "precision": 0.5,
                                              "recall": 0.6666666666666666,
                                              "f1-score": 0.5714285714285715,
                                              "support": 3
                       },
                       "comp.os.ms-windows.misc": {
                                              "precision": 0.16666666666666666,
                                              "recall": 0.1111111111111111,
                                              "f1-score": 0.13333333333333333,
                                              "support": 9
                       },
                       "comp.graphics": {
                                              "precision": 0.5844155844155844,
                                              "recall": 0.7142857142857143,
                                              "f1-score": 0.6428571428571429,
                                              "support": 63
                       },
                       "talk.religion.misc": {
                                              "precision": 0.0,
                                              "recall": 0.0,
                                              "f1-score": 0.0,
                                              "support": 4
                       },
                       "rec.sport.hockey": {
                                              "precision": 1.0,
                                              "recall": 0.16666666666666666,
                                              "f1-score": 0.2857142857142857,
                                              "support": 6
                       },
                       "misc.forsale": {
                                              "precision": 0.7457627118644068,
                                              "recall": 0.7333333333333333,
                                              "f1-score": 0.7394957983193278,
                                              "support": 60
                       },
                       "comp.windows.x": {
                                              "precision": 0.0,
                                              "recall": 0.0,
                                              "f1-score": 0.0,
                                              "support": 5
                       },
                       "rec.motorcycles": {
                                              "precision": 0.7924528301886793,
                                              "recall": 0.7,
                                              "f1-score": 0.743362831858407,
                                              "support": 60
                       },
                       "talk.politics.misc": {
                                              "precision": 0.2857142857142857,
                                              "recall": 0.18181818181818182,
                                              "f1-score": 0.2222222222222222,
                                              "support": 11
                       },
                       "soc.religion.christian": {
                                              "precision": 0.4444444444444444,
                                              "recall": 0.5,
                                              "f1-score": 0.47058823529411764,
                                              "support": 8
                       },
                       "sci.med": {
                                              "precision": 0.6,
                                              "recall": 0.8571428571428571,
                                              "f1-score": 0.7058823529411764,
                                              "support": 7
                       },
                       "talk.politics.guns": {
                                              "precision": 0.16666666666666666,
                                              "recall": 0.125,
                                              "f1-score": 0.14285714285714288,
                                              "support": 8
                       },
                       "rec.autos": {
                                              "precision": 0.625,
                                              "recall": 0.45454545454545453,
                                              "f1-score": 0.5263157894736842,
                                              "support": 11
                       },
                       "accuracy": 0.6125,
                       "macro avg": {
                                              "precision": 0.3994673813083549,
                                              "recall": 0.38014610389610387,
                                              "f1-score": 0.36889262266761924,
                                              "support": 400
                       },
                       "weighted avg": {
                                              "precision": 0.5898049034814385,
                                              "recall": 0.6125,
                                              "f1-score": 0.5908435465298663,
                                              "support": 400
                       }
}{
 "runtime": 117.84134546481073
}{
                       "alt.atheism": {
                                              "precision": 0.23076923076923078,
                                              "recall": 0.3333333333333333,
                                              "f1-score": 0.27272727272727276,
                                              "support": 9
                       },
                       "sci.electronics": {
                                              "precision": 0.2857142857142857,
                                              "recall": 0.2857142857142857,
                                              "f1-score": 0.2857142857142857,
                                              "support": 7
                       },
                       "sci.crypt": {
                                              "precision": 0.0,
                                              "recall": 0.0,
                                              "f1-score": 0.0,
                                              "support": 4
                       },
                       "comp.sys.mac.hardware": {
                                              "precision": 0.7027027027027027,
                                              "recall": 0.4727272727272727,
                                              "f1-score": 0.5652173913043479,
                                              "support": 55
                       },
                       "rec.sport.baseball": {
                                              "precision": 0.7727272727272727,
                                              "recall": 0.8095238095238095,
                                              "f1-score": 0.7906976744186046,
                                              "support": 63
                       },
                       "comp.sys.ibm.pc.hardware": {
                                              "precision": 1.0,
                                              "recall": 0.16666666666666666,
                                              "f1-score": 0.2857142857142857,
                                              "support": 6
                       },
                       "talk.politics.mideast": {
                                              "precision": 0.0,
                                              "recall": 0.0,
                                              "f1-score": 0.0,
                                              "support": 1
                       },
                       "sci.space": {
                                              "precision": 0.5,
                                              "recall": 0.25,
                                              "f1-score": 0.3333333333333333,
                                              "support": 4
                       },
                       "comp.os.ms-windows.misc": {
                                              "precision": 0.3333333333333333,
                                              "recall": 0.1111111111111111,
                                              "f1-score": 0.16666666666666666,
                                              "support": 9
                       },
                       "comp.graphics": {
                                              "precision": 0.4782608695652174,
                                              "recall": 0.7096774193548387,
                                              "f1-score": 0.5714285714285714,
                                              "support": 62
                       },
                       "talk.religion.misc": {
                                              "precision": 0.0,
                                              "recall": 0.0,
                                              "f1-score": 0.0,
                                              "support": 3
                       },
                       "rec.sport.hockey": {
                                              "precision": 0.2857142857142857,
                                              "recall": 0.3333333333333333,
                                              "f1-score": 0.30769230769230765,
                                              "support": 6
                       },
                       "misc.forsale": {
                                              "precision": 0.6896551724137931,
                                              "recall": 0.6557377049180327,
                                              "f1-score": 0.6722689075630253,
                                              "support": 61
                       },
                       "comp.windows.x": {
                                              "precision": 0.0,
                                              "recall": 0.0,
                                              "f1-score": 0.0,
                                              "support": 6
                       },
                       "rec.motorcycles": {
                                              "precision": 0.5666666666666667,
                                              "recall": 0.5666666666666667,
                                              "f1-score": 0.5666666666666667,
                                              "support": 60
                       },
                       "talk.politics.misc": {
                                              "precision": 0.26666666666666666,
                                              "recall": 0.36363636363636365,
                                              "f1-score": 0.30769230769230765,
                                              "support": 11
                       },
                       "soc.religion.christian": {
                                              "precision": 0.6,
                                              "recall": 0.375,
                                              "f1-score": 0.4615384615384615,
                                              "support": 8
                       },
                       "sci.med": {
                                              "precision": 0.5,
                                              "recall": 0.5,
                                              "f1-score": 0.5,
                                              "support": 6
                       },
                       "talk.politics.guns": {
                                              "precision": 0.3333333333333333,
                                              "recall": 0.375,
                                              "f1-score": 0.35294117647058826,
                                              "support": 8
                       },
                       "rec.autos": {
                                              "precision": 0.3076923076923077,
                                              "recall": 0.36363636363636365,
                                              "f1-score": 0.33333333333333337,
                                              "support": 11
                       },
                       "accuracy": 0.555,
                       "macro avg": {
                                              "precision": 0.39266180636495474,
                                              "recall": 0.3335882165311039,
                                              "f1-score": 0.3386816321132029,
                                              "support": 400
                       },
                       "weighted avg": {
                                              "precision": 0.5665685760914397,
                                              "recall": 0.555,
                                              "f1-score": 0.5468833057592498,
                                              "support": 400
                       }
}{
 "runtime": 125.75113554298878
}{
                       "alt.atheism": {
                                              "precision": 0.2857142857142857,
                                              "recall": 0.6666666666666666,
                                              "f1-score": 0.4,
                                              "support": 9
                       },
                       "sci.electronics": {
                                              "precision": 0.0,
                                              "recall": 0.0,
                                              "f1-score": 0.0,
                                              "support": 7
                       },
                       "sci.crypt": {
                                              "precision": 0.0,
                                              "recall": 0.0,
                                              "f1-score": 0.0,
                                              "support": 4
                       },
                       "comp.sys.mac.hardware": {
                                              "precision": 0.5869565217391305,
                                              "recall": 0.4909090909090909,
                                              "f1-score": 0.5346534653465347,
                                              "support": 55
                       },
                       "rec.sport.baseball": {
                                              "precision": 0.8275862068965517,
                                              "recall": 0.7619047619047619,
                                              "f1-score": 0.7933884297520662,
                                              "support": 63
                       },
                       "comp.sys.ibm.pc.hardware": {
                                              "precision": 0.0,
                                              "recall": 0.0,
                                              "f1-score": 0.0,
                                              "support": 6
                       },
                       "talk.politics.mideast": {
                                              "precision": 0.0,
                                              "recall": 0.0,
                                              "f1-score": 0.0,
                                              "support": 2
                       },
                       "sci.space": {
                                              "precision": 0.3333333333333333,
                                              "recall": 0.25,
                                              "f1-score": 0.28571428571428575,
                                              "support": 4
                       },
                       "comp.os.ms-windows.misc": {
                                              "precision": 0.5,
                                              "recall": 0.1111111111111111,
                                              "f1-score": 0.1818181818181818,
                                              "support": 9
                       },
                       "comp.graphics": {
                                              "precision": 0.5161290322580645,
                                              "recall": 0.7741935483870968,
                                              "f1-score": 0.6193548387096774,
                                              "support": 62
                       },
                       "talk.religion.misc": {
                                              "precision": 0.375,
                                              "recall": 1.0,
                                              "f1-score": 0.5454545454545454,
                                              "support": 3
                       },
                       "rec.sport.hockey": {
                                              "precision": 0.2,
                                              "recall": 0.2857142857142857,
                                              "f1-score": 0.23529411764705882,
                                              "support": 7
                       },
                       "misc.forsale": {
                                              "precision": 0.7413793103448276,
                                              "recall": 0.7049180327868853,
                                              "f1-score": 0.7226890756302522,
                                              "support": 61
                       },
                       "comp.windows.x": {
                                              "precision": 0.0,
                                              "recall": 0.0,
                                              "f1-score": 0.0,
                                              "support": 5
                       },
                       "rec.motorcycles": {
                                              "precision": 0.6206896551724138,
                                              "recall": 0.6,
                                              "f1-score": 0.6101694915254238,
                                              "support": 60
                       },
                       "talk.politics.misc": {
                                              "precision": 0.2,
                                              "recall": 0.09090909090909091,
                                              "f1-score": 0.12500000000000003,
                                              "support": 11
                       },
                       "soc.religion.christian": {
                                              "precision": 0.3333333333333333,
                                              "recall": 0.42857142857142855,
                                              "f1-score": 0.375,
                                              "support": 7
                       },
                       "sci.med": {
                                              "precision": 0.42857142857142855,
                                              "recall": 0.42857142857142855,
                                              "f1-score": 0.42857142857142855,
                                              "support": 7
                       },
                       "talk.politics.guns": {
                                              "precision": 0.25,
                                              "recall": 0.14285714285714285,
                                              "f1-score": 0.18181818181818182,
                                              "support": 7
                       },
                       "rec.autos": {
                                              "precision": 0.4166666666666667,
                                              "recall": 0.45454545454545453,
                                              "f1-score": 0.43478260869565216,
                                              "support": 11
                       },
                       "accuracy": 0.57,
                       "macro avg": {
                                              "precision": 0.3307679887015018,
                                              "recall": 0.3595436021467222,
                                              "f1-score": 0.32368543253416443,
                                              "support": 400
                       },
                       "weighted avg": {
                                              "precision": 0.559206213857357,
                                              "recall": 0.57,
                                              "f1-score": 0.5530039849522592,
                                              "support": 400
                       }
}{
 "runtime": 119.77938562259078
}{
                       "alt.atheism": {
                                              "precision": 0.375,
                                              "recall": 0.3333333333333333,
                                              "f1-score": 0.35294117647058826,
                                              "support": 9
                       },
                       "sci.electronics": {
                                              "precision": 0.0,
                                              "recall": 0.0,
                                              "f1-score": 0.0,
                                              "support": 7
                       },
                       "sci.crypt": {
                                              "precision": 1.0,
                                              "recall": 0.25,
                                              "f1-score": 0.4,
                                              "support": 4
                       },
                       "comp.sys.mac.hardware": {
                                              "precision": 0.3238095238095238,
                                              "recall": 0.6181818181818182,
                                              "f1-score": 0.42500000000000004,
                                              "support": 55
                       },
                       "rec.sport.baseball": {
                                              "precision": 0.9166666666666666,
                                              "recall": 0.6984126984126984,
                                              "f1-score": 0.7927927927927927,
                                              "support": 63
                       },
                       "comp.sys.ibm.pc.hardware": {
                                              "precision": 0.0,
                                              "recall": 0.0,
                                              "f1-score": 0.0,
                                              "support": 6
                       },
                       "talk.politics.mideast": {
                                              "precision": 1.0,
                                              "recall": 0.5,
                                              "f1-score": 0.6666666666666666,
                                              "support": 2
                       },
                       "sci.space": {
                                              "precision": 1.0,
                                              "recall": 0.25,
                                              "f1-score": 0.4,
                                              "support": 4
                       },
                       "comp.os.ms-windows.misc": {
                                              "precision": 0.16666666666666666,
                                              "recall": 0.1111111111111111,
                                              "f1-score": 0.13333333333333333,
                                              "support": 9
                       },
                       "comp.graphics": {
                                              "precision": 0.5494505494505495,
                                              "recall": 0.8064516129032258,
                                              "f1-score": 0.6535947712418301,
                                              "support": 62
                       },
                       "talk.religion.misc": {
                                              "precision": 0.0,
                                              "recall": 0.0,
                                              "f1-score": 0.0,
                                              "support": 3
                       },
                       "rec.sport.hockey": {
                                              "precision": 1.0,
                                              "recall": 0.42857142857142855,
                                              "f1-score": 0.6,
                                              "support": 7
                       },
                       "misc.forsale": {
                                              "precision": 0.6785714285714286,
                                              "recall": 0.6229508196721312,
                                              "f1-score": 0.6495726495726496,
                                              "support": 61
                       },
                       "comp.windows.x": {
                                              "precision": 0.0,
                                              "recall": 0.0,
                                              "f1-score": 0.0,
                                              "support": 5
                       },
                       "rec.motorcycles": {
                                              "precision": 0.6041666666666666,
                                              "recall": 0.48333333333333334,
                                              "f1-score": 0.537037037037037,
                                              "support": 60
                       },
                       "talk.politics.misc": {
                                              "precision": 0.5,
                                              "recall": 0.09090909090909091,
                                              "f1-score": 0.15384615384615385,
                                              "support": 11
                       },
                       "soc.religion.christian": {
                                              "precision": 0.6,
                                              "recall": 0.42857142857142855,
                                              "f1-score": 0.5,
                                              "support": 7
                       },
                       "sci.med": {
                                              "precision": 0.3333333333333333,
                                              "recall": 0.2857142857142857,
                                              "f1-score": 0.30769230769230765,
                                              "support": 7
                       },
                       "talk.politics.guns": {
                                              "precision": 0.25,
                                              "recall": 0.14285714285714285,
                                              "f1-score": 0.18181818181818182,
                                              "support": 7
                       },
                       "rec.autos": {
                                              "precision": 0.3333333333333333,
                                              "recall": 0.36363636363636365,
                                              "f1-score": 0.34782608695652173,
                                              "support": 11
                       },
                       "accuracy": 0.54,
                       "macro avg": {
                                              "precision": 0.4815499084249084,
                                              "recall": 0.3207017233603696,
                                              "f1-score": 0.35510605787140304,
                                              "support": 400
                       },
                       "weighted avg": {
                                              "precision": 0.5664832875457875,
                                              "recall": 0.54,
                                              "f1-score": 0.5281118690151619,
                                              "support": 400
                       }
}{
 "runtime": 119.3733297213912
}{
                       "alt.atheism": {
                                              "precision": 0.25,
                                              "recall": 0.5555555555555556,
                                              "f1-score": 0.3448275862068966,
                                              "support": 9
                       },
                       "sci.electronics": {
                                              "precision": 0.3333333333333333,
                                              "recall": 0.14285714285714285,
                                              "f1-score": 0.2,
                                              "support": 7
                       },
                       "sci.crypt": {
                                              "precision": 0.0,
                                              "recall": 0.0,
                                              "f1-score": 0.0,
                                              "support": 4
                       },
                       "comp.sys.mac.hardware": {
                                              "precision": 0.4044943820224719,
                                              "recall": 0.6545454545454545,
                                              "f1-score": 0.5,
                                              "support": 55
                       },
                       "rec.sport.baseball": {
                                              "precision": 0.819672131147541,
                                              "recall": 0.7936507936507936,
                                              "f1-score": 0.8064516129032259,
                                              "support": 63
                       },
                       "comp.sys.ibm.pc.hardware": {
                                              "precision": 0.0,
                                              "recall": 0.0,
                                              "f1-score": 0.0,
                                              "support": 5
                       },
                       "talk.politics.mideast": {
                                              "precision": 0.0,
                                              "recall": 0.0,
                                              "f1-score": 0.0,
                                              "support": 2
                       },
                       "sci.space": {
                                              "precision": 0.5,
                                              "recall": 0.3333333333333333,
                                              "f1-score": 0.4,
                                              "support": 3
                       },
                       "comp.os.ms-windows.misc": {
                                              "precision": 0.25,
                                              "recall": 0.1111111111111111,
                                              "f1-score": 0.15384615384615383,
                                              "support": 9
                       },
                       "comp.graphics": {
                                              "precision": 0.5454545454545454,
                                              "recall": 0.5714285714285714,
                                              "f1-score": 0.5581395348837208,
                                              "support": 63
                       },
                       "talk.religion.misc": {
                                              "precision": 0.25,
                                              "recall": 0.25,
                                              "f1-score": 0.25,
                                              "support": 4
                       },
                       "rec.sport.hockey": {
                                              "precision": 0.5,
                                              "recall": 0.16666666666666666,
                                              "f1-score": 0.25,
                                              "support": 6
                       },
                       "misc.forsale": {
                                              "precision": 0.6129032258064516,
                                              "recall": 0.6229508196721312,
                                              "f1-score": 0.6178861788617885,
                                              "support": 61
                       },
                       "comp.windows.x": {
                                              "precision": 0.5,
                                              "recall": 0.2,
                                              "f1-score": 0.28571428571428575,
                                              "support": 5
                       },
                       "rec.motorcycles": {
                                              "precision": 0.6956521739130435,
                                              "recall": 0.5333333333333333,
                                              "f1-score": 0.6037735849056605,
                                              "support": 60
                       },
                       "talk.politics.misc": {
                                              "precision": 0.75,
                                              "recall": 0.2727272727272727,
                                              "f1-score": 0.39999999999999997,
                                              "support": 11
                       },
                       "soc.religion.christian": {
                                              "precision": 0.4,
                                              "recall": 0.25,
                                              "f1-score": 0.3076923076923077,
                                              "support": 8
                       },
                       "sci.med": {
                                              "precision": 0.3333333333333333,
                                              "recall": 0.2857142857142857,
                                              "f1-score": 0.30769230769230765,
                                              "support": 7
                       },
                       "talk.politics.guns": {
                                              "precision": 0.375,
                                              "recall": 0.375,
                                              "f1-score": 0.375,
                                              "support": 8
                       },
                       "rec.autos": {
                                              "precision": 0.38461538461538464,
                                              "recall": 0.5,
                                              "f1-score": 0.4347826086956522,
                                              "support": 10
                       },
                       "accuracy": 0.545,
                       "macro avg": {
                                              "precision": 0.3952229254813053,
                                              "recall": 0.3309437170297826,
                                              "f1-score": 0.33979030807009997,
                                              "support": 400
                       },
                       "weighted avg": {
                                              "precision": 0.5570980483974102,
                                              "recall": 0.545,
                                              "f1-score": 0.536916400267191,
                                              "support": 400
                       }
}{
 "runtime": 123.07949189096689
}{
     "1": 0.7625113281939191,
     "2": 0.7237645989686069,
     "3": 0.7349639324717172,
     "4": 0.7097387222406155,
     "5": 0.715827867840046
}{
 "overall_perf": 0.7293612899429809
}{
 "overall_runtime": 121.16493764854968
}